import requests
import re
from bs4 import BeautifulSoup

def get_video_url():
    video_url = []
    for page in range(1, 11):
        url = f'https://search.bilibili.com/all?vt=68973445&keyword=日本核污染水排海&page={page}'
        headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.76'
        }
        response = requests.get(url=url, headers=headers)
        response.encoding = 'utf-8'
        content_list = re.findall('bvid:"(.*?)"', response.text)
        video_url += content_list
    return video_url

def get_dm_url(video_url):
    dm_url=[]
    for index in video_url:
        url='https://www.ibilibili.com/video/'+index
        dm_url.append(url)
    return dm_url

def get_danmu_url(dm_url):
    danmu_url=[]
    for url in dm_url:
        response = requests.get(url=url)
        response.encoding = 'utf-8'
        dan_url = re.findall('<a href="(.*?)" class="btn btn-default" target="_blank">弹幕</a>', response.text)
        danmu_url += dan_url

def get_danmu(danmu_url):
    for url in danmu_url:
        response = requests.get(url=url)
        response.encoding = 'utf-8'
        danmu_list = re.findall('</d><d p=".*?">(.*?)</d>', response.text)
        for danmu in danmu_list:
            with open('dm.txt', mode='a', encoding='utf-8') as f:
                f.write(danmu)
                f.write('\n')

import jieba
import wordcloud
f = open('dm.txt', encoding='utf-8')
txt = f.read()
string = ' '.join(jieba.lcut(txt))
wc = wordcloud.WordCloud(
    width=700,
    height=700,
    background_color='white',
    font_path='msyh.ttc',
    scale=15,
)
wc.generate(string)
wc.to_file('dmcy.png')
